<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DSA on PMem.io</title><link>https://pmem.io/tags/dsa/</link><description>Recent content in DSA on PMem.io</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 11 May 2022 10:00:00 +0000</lastBuildDate><atom:link href="https://pmem.io/tags/dsa/index.xml" rel="self" type="application/rss+xml"/><item><title>Upcoming asynchronous interfaces in PMDK libraries</title><link>https://pmem.io/blog/2022/05/upcoming-asynchronous-interfaces-in-pmdk-libraries/</link><pubDate>Wed, 11 May 2022 10:00:00 +0000</pubDate><guid>https://pmem.io/blog/2022/05/upcoming-asynchronous-interfaces-in-pmdk-libraries/</guid><description>In the previous article, I wrote about a new upcoming Xeon platform feature, Data Streaming Accelerator (DSA) - a memory-to-memory DMA engine, and what opportunities and challenges it presents. I outlined the approach we are taking in Persistent Memory Development Kit (PMDK) to expose asynchronous APIs that can take advantage of this new hardware. Lastly, I introduced libminiasync, which is our framework for abstracting asynchronous operations.
This time, I will discuss how miniasync is being used in libpmem2 and our plans for its integration into the rest of PMDK libraries.</description></item><item><title>Leveraging asynchronous hardware accelerators for fun and profit</title><link>https://pmem.io/blog/2022/02/leveraging-asynchronous-hardware-accelerators-for-fun-and-profit/</link><pubDate>Mon, 28 Feb 2022 10:00:00 +0000</pubDate><guid>https://pmem.io/blog/2022/02/leveraging-asynchronous-hardware-accelerators-for-fun-and-profit/</guid><description>One of the greatest benefits of Persistent Memory is that it&amp;rsquo;s directly accessible by the CPU. But that can also be one of its downsides for specific use cases. For example, if you want to use PMem as an ultra-fast storage device with low access latency.
PMem as storage impedance mismatch The reason for that is simple - block storage I/O is typically asynchronous due to its relatively high latency and high queue depths required to reach optimal throughputs.</description></item></channel></rss>