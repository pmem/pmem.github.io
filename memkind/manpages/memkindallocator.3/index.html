<!doctype html><html dir=ltr lang=en-us><head><link rel=stylesheet type=text/css href=/css/style.css><meta property="og:title" content="MEMKINDALLOCATOR"><meta property="og:description" content="TABLE OF CONTENTS NAME
SYNOPSIS
DESCRIPTION
SYSTEM CONFIGURATION
COPYRIGHT
SEE ALSO
NAME libmemkind::static_kind::allocator - The C++ allocator compatible with the C++ standard library allocator concepts.
Note: memkind_allocator.h functionality is considered as a stable API (STANDARD API).
SYNOPSIS #include <memkind_allocator.h> Link with -lmemkind libmemkind::static_kind::allocator(libmemkind::kinds kind); template <typename U> libmemkind::static_kind::allocator<T>::allocator(const libmemkind::static_kind::allocator<U>&) noexcept; template <typename U> libmemkind::static_kind::allocator(const allocator<U>&& other) noexcept; libmemkind::static_kind::allocator<T>::~allocator(); T *libmemkind::static_kind::allocator<T>::allocate(std::size_t n) const; void libmemkind::static_kind::allocator<T>::deallocate(T *p, std::size_t n) const; template <class U, class."><meta property="og:type" content="article"><meta property="og:url" content="https://pmem.io/memkind/manpages/memkindallocator.3/"><meta property="article:section" content="memkind"><meta charset=utf-8><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><title>MEMKINDALLOCATOR</title><meta name=author content="PMem.io"><meta name=description content="Persistent Memory Development Kit (PMDK) provides support for transactional and atomic operations to keep the data consistent and durable.  PMDK is a collection of open-source libraries and tools that are available for both Linux and Windows OS.  PMDK facilitates persistent memory programming adoption with higher level language support.  Currently, Java, Python, Rust, Go, C and C++ support is fully validated and delivered on Linux and Windows.  This new generation of persistent memory from Intel has introduced a third memory tier (memory persistence, memory tiering).  In addition to memory and storage tiers, the persistent memory tier offers greater capacity than DRAM and significantly faster performance than storage.  Applications can access persistent memory-resident data structures in-place, like they do with traditional memory, eliminating the need to page blocks of data back and forth between memory and storage. PMDK provides a toolkit for memory hierarchy, memory caching, virtual memory and memory tiering.  PMDK-PMEM toolkit provides operational modes in either app direct mode or memory mode. App Direct Mode provides memory persistent, high availability less downtime and significantly faster storage.  In memory mode provides high memory capacity at lower cost and is transparent to applications.  Memory is volatile in memory mode and persistent in App Direct mode"><meta name=robots content="index, follow, archive"><link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700,900&display=swap" rel=stylesheet type=text/css><link rel=stylesheet href=/css/bootstrap.css type=text/css><link rel=stylesheet href=/css/style.css type=text/css><link rel=stylesheet href=/css/dark.css type=text/css><link rel=stylesheet href=/css/font-icons.css type=text/css><link rel=stylesheet href=/css/animate.css type=text/css><link rel=stylesheet href=/css/magnific-popup.css type=text/css><link rel=stylesheet href=/css/et-line.css type=text/css><link rel=stylesheet href=/css/components/bs-switches.css type=text/css><link rel=stylesheet href=/css/custom.css type=text/css><meta name=viewport content="initial-scale=1,viewport-fit=cover"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css type=text/css><link rel=stylesheet href="/css/colors.php?color=FE9603" type=text/css><link rel=stylesheet href=/css/template/fonts.css type=text/css><link rel=stylesheet href=/css/template/seo.css type=text/css></head><body class=stretched><div id=wrapper class=clearfix><header id=header class="transparent-header floating-header header-size-md sticky-header"><div id=header-wrap class=dark-mode><div class="container dark-mode"><div class=header-row><div id=logo class=logo_dark><a href=/ class=standard-logo data-dark-logo=images/logo-dark.png><img src=https://pmem.io/images/pmem_logo.png alt=PMem.io></a>
<a href=/ class=retina-logo data-dark-logo=images/logo-dark@2x.png><img src=https://pmem.io/images/pmem_logo.png alt=PMem.io></a></div><div id=logo class=logo_light><a href=/ class=standard-logo data-dark-logo=images/logo-dark.png><img src=https://pmem.io/images/pmem_logo_white.png alt=PMem.io></a>
<a href=/ class=retina-logo data-dark-logo=images/logo-dark@2x.png><img src=https://pmem.io/images/pmem_logo_white.png alt=PMem.io></a></div><div class=header-misc><div id=top-search class=header-misc-icon><a href=# id=top-search-trigger><i class=icon-line-search></i><i class=icon-line-cross></i></a></div><div class=top-links><ul class=top-links-container><li><div id=darkSwitch class="dark-mode header-misc-icon d-md-block"><a href=#><i id=darkSwitchToggle></i></a></div></li></ul></div></div><div id=primary-menu-trigger><svg class="svg-trigger" viewBox="0 0 100 100"><path d="m30 33h40c3.722839.0 7.5 3.126468 7.5 8.578427C77.5 47.030386 74.772971 50 70 50H50"/><path d="m30 50h40"/><path d="m70 67H30s-7.5-.802118-7.5-8.365747C22.5 51.070624 30 50 30 50h20"/></svg></div><nav class="primary-menu with-arrows"><ul class=menu-container><li class="menu-item mega-menu"><div class=menu-link><div><a href=/developer-hub>Developer Hub</a></div></div><div class="mega-menu-content mega-menu-style-2 px-0"><div class="container dark-mode"><div class=row><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class=fbox-content><p class=fw-bold>For Developers</p><p>Everything you need to know about Persistent Memory.</p></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=https://docs.pmem.io/persistent-memory/getting-started-guide><p>Get started <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/pmdk><p>PMDK <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/repoindex><p>PMem Repositories <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/pmemkv><p>PMemKV <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/pmemstream><p>PMemStream <i class=icon-angle-right></i></p></a></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/memkind><p>Memkind <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/miniasync><p>MiniAsync <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/community/#newsletter><p>Newsletter <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://tieredmemdb.github.io/><p>TieredMemDB <i class=icon-angle-right></i></p></a></div></div></div></div></div></div></li><li class="menu-item mega-menu"><div class=menu-link><div><a href=/learn>Learn</a></div></div><div class="mega-menu-content mega-menu-style-2 px-0"><div class="container dark-mode"><div class=row><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class=fbox-content><p class=fw-bold>Access our Documentation</p><p>Learn more about Persistent Memory features and capabilities.</p></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/books><p>Books <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://docs.pmem.io/persistent-memory/><p>Docs <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/glossary><p>Glossary <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://docs.pmem.io/ipmctl-user-guide/><p>ipmctl User Guide <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://docs.pmem.io/ndctl-user-guide/><p>ndctl User Guide <i class=icon-angle-right></i></p></a></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/faq><p>FAQ <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/knowledgebase><p>Knowledge base <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/tutorials><p>Tutorials <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/videos><p>Videos <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/webinars><p>Webinars <i class=icon-angle-right></i></p></a></div></div></div></div></div></div></li><li class="menu-item mega-menu"><div class=menu-link><div><a href=/community>Community</a></div></div><div class="mega-menu-content mega-menu-style-2 px-0"><div class="container dark-mode"><div class=row><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class=fbox-content><p class=fw-bold>Get Connected</p><p>Join an ever-growing community of PMDK-PMEM developers online or in person.</p></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/events><p>Events <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://groups.google.com/group/pmem><p>Forum <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://pmem-io.slack.com/join/shared_invite/enQtNzU4MzQ2Mzk3MDQwLWQ1YThmODVmMGFkZWI0YTdhODg4ODVhODdhYjg3NmE4N2ViZGI5NTRmZTBiNDYyOGJjYTIyNmZjYzQxODcwNDg#/shared-invite/email><p>Slack channel <i class=icon-angle-right></i></p></a></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/announcements><p>Announcements <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/blog/2021/10/how-to-contribute-to-pmem.io/><p>Contribute <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/community/#newsletter><p>Newsletter <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/community/#social-media><p>Social Media <i class=icon-angle-right></i></p></a></div></div></div></div></div></div></li><li class=menu-item><a class=menu-link href=https://pmem.io/solutions><div>Solutions</div></a></li><li class=menu-item><a class=menu-link href=https://pmem.io/blog><div>Blog</div></a></li><li class=menu-item><a class=menu-link href=https://pmem.io/about><div>About</div></a></li></ul></nav><form class=top-search-form method=get><input id=bcs-searchbox aria-label="Search input" type=text name=q class="form-control bcs-searchbox pt-4" placeholder="Type & Hit Enter.." autocomplete=off></form></div></div></div><div class="header-wrap-clone dark-mode"></div></header><div id=customSearch><div id=bcs_js_snippet></div></div><section id=page-title class="page-title-parallax page-title-center page-title-dark include-header skrollable skrollable-between" style="background-image:url('');background-size:cover;padding:120px 0;margin-top:-157.05px"><div class="container clearfix mt-4"><div class="slider-title text-light"><h2 style=color:#fff></h2></div></div></section><div class="section m-0 bg-transparent library-section dark-mode"><div class=container><div class="row justify-content-between"><div class="col mt-0 lib-content"><h1 id=table-of-contents>TABLE OF CONTENTS</h1><p><a href=#name><strong>NAME</strong></a><br><a href=#synopsis><strong>SYNOPSIS</strong></a><br><a href=#description><strong>DESCRIPTION</strong></a><br><a href=#system-configuration><strong>SYSTEM CONFIGURATION</strong></a><br><a href=#copyright><strong>COPYRIGHT</strong></a><br><a href=#see-also><strong>SEE ALSO</strong></a></p><h1 id=name>NAME</h1><p><strong>libmemkind::static_kind::allocator<t></strong> - The C++ allocator compatible with the
C++ standard library allocator concepts.</p><p><strong>Note:</strong> <em>memkind_allocator.h</em> functionality is considered as a stable
API (STANDARD API).</p><h1 id=synopsis>SYNOPSIS</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;memkind_allocator.h&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>Link with <span style=color:#f92672>-</span>lmemkind
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator(libmemkind<span style=color:#f92672>::</span>kinds kind);
</span></span><span style=display:flex><span>template <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>typename</span> U<span style=color:#f92672>&gt;</span> libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator<span style=color:#f92672>&lt;</span>T<span style=color:#f92672>&gt;::</span>allocator(<span style=color:#66d9ef>const</span> libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator<span style=color:#f92672>&lt;</span>U<span style=color:#f92672>&gt;&amp;</span>) noexcept;
</span></span><span style=display:flex><span>template <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>typename</span> U<span style=color:#f92672>&gt;</span> libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator(<span style=color:#66d9ef>const</span> allocator<span style=color:#f92672>&lt;</span>U<span style=color:#f92672>&gt;&amp;&amp;</span> other) noexcept;
</span></span><span style=display:flex><span>libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator<span style=color:#f92672>&lt;</span>T<span style=color:#f92672>&gt;::~</span>allocator();
</span></span><span style=display:flex><span>T <span style=color:#f92672>*</span>libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator<span style=color:#f92672>&lt;</span>T<span style=color:#f92672>&gt;::</span>allocate(std<span style=color:#f92672>::</span>size_t n) <span style=color:#66d9ef>const</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>void</span> libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator<span style=color:#f92672>&lt;</span>T<span style=color:#f92672>&gt;::</span>deallocate(T <span style=color:#f92672>*</span>p, std<span style=color:#f92672>::</span>size_t n) <span style=color:#66d9ef>const</span>;
</span></span><span style=display:flex><span>template <span style=color:#f92672>&lt;</span>class U, class... Args<span style=color:#f92672>&gt;</span> <span style=color:#66d9ef>void</span> libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator<span style=color:#f92672>&lt;</span>T<span style=color:#f92672>&gt;::</span>construct(U <span style=color:#f92672>*</span>p, Args... args) <span style=color:#66d9ef>const</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>void</span> libmemkind<span style=color:#f92672>::</span>static_kind<span style=color:#f92672>::</span>allocator<span style=color:#f92672>&lt;</span>T<span style=color:#f92672>&gt;::</span>destroy(T <span style=color:#f92672>*</span>p) <span style=color:#66d9ef>const</span>;
</span></span></code></pre></div><h1 id=description>DESCRIPTION</h1><dl><dt><code>libmemkind::static_kind::allocator&lt;T></code></dt><dd>is intended to be used with STL containers to allocate from static kinds
of memory. All public member types and functions correspond to standard
library allocator concepts and definitions. The current implementation supports
the C++11 standard.</dd></dl><ul><li>Template arguments:<ul><li>T is an object type aliased by value_type,</li><li>U is an object type. Memory management is based on the memkind library.
Refer to the <a href=/memkind/manpages/memkind.3/><strong>memkind</strong></a>(3) man page for more details.</li></ul></li></ul><dl><dt><code>T *libmemkind::static_kind::allocator&lt;T>::allocate(std::size_t n)</code></dt><dd>allocates uninitialized memory of size <em>n</em> bytes of the specified kind using
<code>memkind_malloc()</code>. Throw <strong>std::bad_alloc</strong> when n = 0 or there is not enough
memory to satisfy the request.</dd><dt><code>libmemkind::static_kind::allocator&lt;T>::deallocate(T *p, std::size_t n)</code></dt><dd>deallocates memory associated with pointer returned by <code>allocate()</code> using <code>memkind_free()</code>.</dd><dt><code>libmemkind::kinds</code></dt><dd>specifies allocator static kinds of memory, representing type of memory which offers
different characteristics. The available types of allocator kinds of memory:</dd></dl><h4 id=types-of-allocator-kinds-of-memory>Types of allocator kinds of memory</h4><dl><dt><code>libmemkind::kinds::DEFAULT</code></dt><dd>The default allocation using standard memory and the default page size.
The allocation can be made using any NUMA node containing memory.</dd><dt><code>libmemkind::kinds::HIGHEST_CAPACITY</code></dt><dd>Allocate from a NUMA node(s) that has the highest capacity among all nodes in the system.</dd><dt><code>libmemkind::kinds::HIGHEST_CAPACITY_PREFERRED</code></dt><dd>Same as <code>libmemkind::kinds::HIGHEST_CAPACITY</code> except that if there is not enough
memory in the NUMA node that has the highest capacity in the local domain to satisfy
the request, the allocation will fall back on other memory NUMA nodes.
<strong>Note:</strong> For this kind, the allocation will not succeed if there are two or more
NUMA nodes that have the highest capacity.</dd><dt>`libmemkind::kinds::HIGHEST_CAPACITY_LOCAL</dt><dd>Allocate from a NUMA node that has the highest capacity among all NUMA Nodes from
the local domain. NUMA Nodes have the same local domain for a set of CPUs associated
with them, e.g. socket or sub-NUMA cluster.
<strong>Note:</strong> If there are multiple NUMA nodes in the same local domain that have the
highest capacity - the allocation will be done from a NUMA node with worse latency
attribute. This kind requires locality information described in the
<a href=#system-configuration>SYSTEM CONFIGURATION</a> section.</dd><dt><code>libmemkind::kinds::HIGHEST_CAPACITY_LOCAL_PREFERRED</code></dt><dd>Same as <code>libmemkind::kinds::HIGHEST_CAPACITY_LOCAL</code> except that if there is not enough
memory in the NUMA node that has the highest capacity to satisfy the request, the
allocation will fall back on other memory NUMA nodes.</dd><dt><code>libmemkind::kinds::LOWEST_LATENCY_LOCAL</code></dt><dd>Allocate from a NUMA node that has the lowest latency among all NUMA Nodes
from the local domain. NUMA Nodes have the same local domain for a set of CPUs
associated with them, e.g. socket or sub-NUMA cluster.
<strong>Note:</strong> If there are multiple NUMA nodes in the same local domain that
have the lowest latency - the allocation will be done from a NUMA node with
smaller memory capacity. This kind requires locality and memory performance
characteristics information described in the
<a href=#system-configuration>SYSTEM CONFIGURATION</a> section.</dd><dt><code>libmemkind::kinds::LOWEST_LATENCY_LOCAL_PREFERRED</code></dt><dd>Same as <code>libmemkind::kinds::LOWEST_LATENCY_LOCAL</code> except that if there is not
enough memory in the NUMA node that has the lowest latency to satisfy the request,
the allocation will fall back on other memory NUMA nodes.</dd><dt><code>libmemkind::kinds::HIGHEST_BANDWIDTH_LOCAL</code></dt><dd>Allocate from a NUMA node that has the highest bandwidth among all NUMA Nodes
from the local domain. NUMA Nodes have the same local domain for a set of CPUs
associated with them, e.g. socket or sub-NUMA cluster.
<strong>Note:</strong> If there are multiple NUMA nodes in the same local domain that have
the highest bandwidth - the allocation will be done from a NUMA node with
smaller memory capacity. This kind requires locality and memory performance
characteristics information described in the
<a href=#system-configuration>SYSTEM CONFIGURATION</a> section.</dd><dt><code>libmemkind::kinds::HIGHEST_BANDWIDTH_LOCAL_PREFERRED</code></dt><dd>Same as <code>libmemkind::kinds::HIGHEST_BANDWIDTH_LOCAL</code> except that if there
is not enough memory in the NUMA node that has the highest bandwidth to satisfy
the request, the allocation will fall back on other memory NUMA nodes.</dd><dt><code>libmemkind::kinds::HUGETLB</code></dt><dd>Allocate from standard memory using huge pages.
<strong>Note:</strong> This kind requires huge pages configuration described in the
<a href=#system-configuration>SYSTEM CONFIGURATION</a> section.</dd><dt><code>libmemkind::kinds::INTERLEAVE</code></dt><dd>Allocate pages interleaved across all NUMA nodes with transparent
huge pages disabled.</dd><dt><code>libmemkind::kinds::HBW</code></dt><dd>Allocate from the closest high bandwidth memory NUMA node at the time of
allocation. If there is not enough high bandwidth memory to satisfy the request,
<em>errno</em> is set to <strong>ENOMEM</strong> and the allocated pointer is set to NULL.
<strong>Note:</strong> This kind requires memory performance characteristics information
described in the <a href=#system-configuration>SYSTEM CONFIGURATION</a> section.</dd><dt><code>libmemkind::kinds::HBW_ALL</code></dt><dd>Same as <code>libmemkind::kinds::HBW</code> except decision regarding closest NUMA node
is postponed until the time of the first write.</dd><dt><code>libmemkind::kinds::HBW_HUGETLB</code></dt><dd>Same as <code>libmemkind::kinds::HBW</code> except the allocation is backed by huge pages.
Note: This kind requires huge pages configuration described in the
<a href=#system-configuration>SYSTEM CONFIGURATION</a> section.</dd><dt><code>libmemkind::kinds::HBW_ALL_HUGETLB</code></dt><dd>Combination of <code>libmemkind::kinds::HBW_ALL</code> and <code>libmemkind::kinds::HBW_HUGETLB</code>
properties.
<strong>Note:</strong> This kind requires huge pages configuration described in the
<a href=#system-configuration>SYSTEM CONFIGURATION</a> section.</dd><dt><code>libmemkind::kinds::HBW_PREFERRED</code></dt><dd>Same as <code>libmemkind::kinds::HBW</code> except that if there is not enough high
bandwidth memory to satisfy the request, the allocation will fall back on
standard memory.</dd><dt><code>libmemkind::kinds::HBW_PREFERRED_HUGETLB</code></dt><dd>Same as <code>libmemkind::kinds::HBW_PREFERRED</code> except the allocation is backed by
huge pages.
<strong>Note:</strong> This kind requires huge pages configuration described in the
<a href=#system-configuration>SYSTEM CONFIGURATION</a> section.</dd><dt><code>libmemkind::kinds::HBW_INTERLEAVE</code></dt><dd>Same as <code>libmemkind::kinds::HBW</code> except that the pages that support the
allocation are interleaved across all high bandwidth nodes and transparent huge
pages are disabled.</dd><dt><code>libmemkind::kinds::REGULAR</code></dt><dd>Allocate from regular memory using the default page size. Regular means
general purpose memory from the NUMA nodes containing CPUs.</dd><dt><code>libmemkind::kinds::DAX_KMEM</code></dt><dd>Allocate from the closest persistent memory NUMA node at the time of allocation.
If there is not enough memory in the closest persistent memory NUMA node to
satisfy the request, <em>errno</em> is set to <strong>ENOMEM</strong> and the allocated pointer is set
to NULL.</dd><dt><code>libmemkind::kinds::DAX_KMEM_ALL</code></dt><dd>Allocate from the closest persistent memory NUMA node available at the time of
allocation. If there is not enough memory on any of persistent memory NUMA nodes
to satisfy the request, <em>errno</em> is set to <strong>ENOMEM</strong> and the allocated pointer is set
to NULL.</dd><dt><code>libmemkind::kinds::DAX_KMEM_PREFERRED</code></dt><dd>Same as <code>libmemkind::kinds::DAX_KMEM</code> except that if there is not enough memory
in the closest persistent memory NUMA node to satisfy the request, the allocation
will fall back on other memory NUMA nodes.
<strong>Note:</strong> For this kind, the allocation will not succeed if two or more persistent
memory NUMA nodes are in the same shortest distance to the same CPU on which process
is eligible to run. Check on that eligibility is done upon starting the application.</dd><dt><code>libmemkind::kinds::DAX_KMEM_INTERLEAVE</code></dt><dd>Same as <code>libmemkind::kinds::DAX_KMEM</code> except that the pages that support the
allocation are interleaved across all persistent memory NUMA nodes.</dd></dl><h1 id=system-configuration>SYSTEM CONFIGURATION</h1><dl><dt>HUGETLB (huge pages)</dt><dd>Interfaces for obtaining 2MB (<strong>HUGETLB</strong>) memory need allocated huge pages in the
kernelâ€™s huge page pool.
Current number of &ldquo;persistent&rdquo; huge pages can be read from the <em>/proc/sys/vm/nr_hugepages</em> file.
Proposed way of setting hugepages is: <code>sudo sysctl vm.nr_hugepages=&lt;number_of_hugepages></code>.
More information can be found here: <a href=https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt>https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt</a></dd><dt>Locality information</dt><dd>Interfaces for obtaining locality information are provided by <em>libhwloc</em> dependency.
Functionality based on locality requires that memkind library is configured
and built with the support of the <a href=https://www.open-mpi.org/projects/hwloc><em>libhwloc</em></a> :<br><code>./configure --enable-hwloc</code></dd><dt>Memory performance characteristics information</dt><dd>Interfaces for obtaining memory performance characteristics information are based on <em>HMAT</em>
(Heterogeneous Memory Attribute Table). See
<a href=https://uefi.org/sites/default/files/resources/ACPI_6_3_final_Jan30.pdf>https://uefi.org/sites/default/files/resources/ACPI_6_3_final_Jan30.pdf</a> for more information.
Functionality based on memory performance characteristics requires that platform configuration
fully supports <em>HMAT</em> and memkind library is configured and built with the support of the
<a href=https://www.open-mpi.org/projects/hwloc><em>libhwloc</em></a> :<br><code>./configure --enable-hwloc</code></dd></dl><p><strong>Note:</strong> For a given target NUMA Node, the OS exposes only the performance
characteristics of the best performing NUMA node.</p><p><em>libhwloc</em> can be reached on: <a href=https://www.open-mpi.org/projects/hwloc>https://www.open-mpi.org/projects/hwloc</a></p><h1 id=copyright>COPYRIGHT</h1><p>Copyright (C) 2019 - 2022 Intel Corporation. All rights reserved.</p><h1 id=see-also>SEE ALSO</h1><p><a href=/memkind/manpages/memkind.3/><strong>memkind</strong></a>(3)</p></div></div><div class=divider></div><p class=text-center><small>The contents of this web site and the associated <a href=https://github.com/memkind>GitHub repositories</a> are BSD-licensed open source.</small></p></div></div><footer id=footer class="border-0 bg-white"><div id=copyrights><div class="container clearfix"><div class="row justify-content-between col-mb-30"><div class="col-12 col-lg-auto text-center text-lg-start"><div id=logo><a href=/ class=standard-logo data-dark-logo=images/logo-dark.png><img src=https://pmem.io/images/pmem_logo.png alt="PMem Logo"></a>
<a href=/ class=retina-logo data-dark-logo=images/logo-dark@2x.png><img src=https://pmem.io/images/pmem_logo.png alt="PMem Logo"></a></div></div><div class="col-12 col-lg-auto text-center text-lg-end"><div class="copyrights-menu copyright-links clearfix text-uppercase"><a href=https://pmem.io/about>about</a>/
<a href=https://pmem.io/blog>blog</a>/
<a href=https://pmem.io/community>community</a>/
<a href=https://pmem.io/cookies.html>Cookies</a>/
<a href=https://pmem.io/developer-hub>developer Hub</a>/
<a href=https://pmem.io/learn>learn</a>/
<a href=https://pmem.io/privacy.html>Privacy</a>/
<a href=https://pmem.io/solutions>solutions</a>/
<a href=https://pmem.io/terms.html>Terms</a></div><div class="col-lg-auto text-center mt-0"><p>Copyright &copy; 2022 pmem.io</p></div></div></div></div></div></footer></div><div id=gotoTop class=icon-angle-up></div><script src=/js/jquery.js></script>
<script src=/js/plugins.min.js></script>
<script src=/js/custom.js></script>
<script src=/js/darkmode.js></script>
<script src=/js/functions.js></script>
<script type=text/javascript src="https://ui.customsearch.ai/api/ux/rendering-js?customConfig=011a90aa-26ea-46b5-bf60-4b5b407c72c6&market=en-US&version=latest&q="></script></body></html>