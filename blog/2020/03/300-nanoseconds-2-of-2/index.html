<!doctype html><html dir=ltr lang=en-us><head><link rel=stylesheet type=text/css href=/css/style.css><meta property="og:title" content="300 nanoseconds (2 of 2)"><meta property="og:description" content="At the end of the first part of this blog series, I posed three fundamental questions regarding the design of failure atomic data structures for persistent memory.
What does it mean to allocate persistent memory? How to do fail-safe atomic updates? Are all data structures suitable for persistent memory? This time around, I will try to answer these questions to the best of my ability. We will return to the doubly-linked list example to see how it can be modified for PMEM."><meta property="og:type" content="article"><meta property="og:url" content="https://pmem.io/blog/2020/03/300-nanoseconds-2-of-2/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2020-03-26T19:55:17-07:00"><meta property="article:modified_time" content="2020-03-26T19:55:17-07:00"><meta charset=utf-8><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><title>300 nanoseconds (2 of 2)</title><meta name=author content="PMem.io"><meta name=description content="Persistent Memory Development Kit (PMDK) provides support for transactional and atomic operations to keep the data consistent and durable.  PMDK is a collection of open-source libraries and tools that are available for both Linux and Windows OS.  PMDK facilitates persistent memory programming adoption with higher level language support.  Currently, Java, Python, Rust, Go, C and C++ support is fully validated and delivered on Linux and Windows.  This new generation of persistent memory from Intel has introduced a third memory tier (memory persistence, memory tiering).  In addition to memory and storage tiers, the persistent memory tier offers greater capacity than DRAM and significantly faster performance than storage.  Applications can access persistent memory-resident data structures in-place, like they do with traditional memory, eliminating the need to page blocks of data back and forth between memory and storage. PMDK provides a toolkit for memory hierarchy, memory caching, virtual memory and memory tiering.  PMDK-PMEM toolkit provides operational modes in either app direct mode or memory mode. App Direct Mode provides memory persistent, high availability less downtime and significantly faster storage.  In memory mode provides high memory capacity at lower cost and is transparent to applications.  Memory is volatile in memory mode and persistent in App Direct mode"><meta name=robots content="index, follow, archive"><link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700,900&display=swap" rel=stylesheet type=text/css><link rel=stylesheet href=/css/bootstrap.css type=text/css><link rel=stylesheet href=/css/style.css type=text/css><link rel=stylesheet href=/css/dark.css type=text/css><link rel=stylesheet href=/css/font-icons.css type=text/css><link rel=stylesheet href=/css/animate.css type=text/css><link rel=stylesheet href=/css/magnific-popup.css type=text/css><link rel=stylesheet href=/css/et-line.css type=text/css><link rel=stylesheet href=/css/components/bs-switches.css type=text/css><link rel=stylesheet href=/css/custom.css type=text/css><meta name=viewport content="initial-scale=1,viewport-fit=cover"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css type=text/css><link rel=stylesheet href="/css/colors.php?color=FE9603" type=text/css><link rel=stylesheet href=/css/template/fonts.css type=text/css><link rel=stylesheet href=/css/template/seo.css type=text/css></head><body class=stretched><div id=wrapper class=clearfix><header id=header class="transparent-header floating-header header-size-md sticky-header"><div id=header-wrap class=dark-mode><div class="container dark-mode"><div class=header-row><div id=logo class=logo_dark><a href=/ class=standard-logo data-dark-logo=images/logo-dark.png><img src=https://pmem.io/images/pmem_logo.png alt=PMem.io></a>
<a href=/ class=retina-logo data-dark-logo=images/logo-dark@2x.png><img src=https://pmem.io/images/pmem_logo.png alt=PMem.io></a></div><div id=logo class=logo_light><a href=/ class=standard-logo data-dark-logo=images/logo-dark.png><img src=https://pmem.io/images/pmem_logo_white.png alt=PMem.io></a>
<a href=/ class=retina-logo data-dark-logo=images/logo-dark@2x.png><img src=https://pmem.io/images/pmem_logo_white.png alt=PMem.io></a></div><div class=header-misc><div id=top-search class=header-misc-icon><a href=# id=top-search-trigger><i class=icon-line-search></i><i class=icon-line-cross></i></a></div><div class=top-links><ul class=top-links-container><li><div id=darkSwitch class="dark-mode header-misc-icon d-md-block"><a href=#><i id=darkSwitchToggle></i></a></div></li></ul></div></div><div id=primary-menu-trigger><svg class="svg-trigger" viewBox="0 0 100 100"><path d="m30 33h40c3.722839.0 7.5 3.126468 7.5 8.578427C77.5 47.030386 74.772971 50 70 50H50"/><path d="m30 50h40"/><path d="m70 67H30s-7.5-.802118-7.5-8.365747C22.5 51.070624 30 50 30 50h20"/></svg></div><nav class="primary-menu with-arrows"><ul class=menu-container><li class="menu-item mega-menu"><div class=menu-link><div><a href=/developer-hub>Developer Hub</a></div></div><div class="mega-menu-content mega-menu-style-2 px-0"><div class="container dark-mode"><div class=row><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class=fbox-content><p class=fw-bold>For Developers</p><p>Everything you need to know about Persistent Memory.</p></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=https://docs.pmem.io/persistent-memory/getting-started-guide><p>Get started <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/pmdk><p>PMDK <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/repoindex><p>PMem Repositories <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/pmemkv><p>PMemKV <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/pmemstream><p>PMemStream <i class=icon-angle-right></i></p></a></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/memkind><p>Memkind <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/miniasync><p>MiniAsync <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/community/#newsletter><p>Newsletter <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://tieredmemdb.github.io/><p>TieredMemDB <i class=icon-angle-right></i></p></a></div></div></div></div></div></div></li><li class="menu-item mega-menu"><div class=menu-link><div><a href=/learn>Learn</a></div></div><div class="mega-menu-content mega-menu-style-2 px-0"><div class="container dark-mode"><div class=row><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class=fbox-content><p class=fw-bold>Access our Documentation</p><p>Learn more about Persistent Memory features and capabilities.</p></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/books><p>Books <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://docs.pmem.io/persistent-memory/><p>Docs <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/glossary><p>Glossary <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://docs.pmem.io/ipmctl-user-guide/><p>ipmctl User Guide <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://docs.pmem.io/ndctl-user-guide/><p>ndctl User Guide <i class=icon-angle-right></i></p></a></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/faq><p>FAQ <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/knowledgebase><p>Knowledge base <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/tutorials><p>Tutorials <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/videos><p>Videos <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/webinars><p>Webinars <i class=icon-angle-right></i></p></a></div></div></div></div></div></div></li><li class="menu-item mega-menu"><div class=menu-link><div><a href=/community>Community</a></div></div><div class="mega-menu-content mega-menu-style-2 px-0"><div class="container dark-mode"><div class=row><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class=fbox-content><p class=fw-bold>Get Connected</p><p>Join an ever-growing community of PMDK-PMEM developers online or in person.</p></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/events><p>Events <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://groups.google.com/group/pmem><p>Forum <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=https://pmem-io.slack.com/join/shared_invite/enQtNzU4MzQ2Mzk3MDQwLWQ1YThmODVmMGFkZWI0YTdhODg4ODVhODdhYjg3NmE4N2ViZGI5NTRmZTBiNDYyOGJjYTIyNmZjYzQxODcwNDg#/shared-invite/email><p>Slack channel <i class=icon-angle-right></i></p></a></div></div></div><div class="mega-menu-column sub-menu-container col-lg-4 border-bottom py-4"><div class=feature-box><div class="fbox-content h-bg-light"><a href=/announcements><p>Announcements <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/blog/2021/10/how-to-contribute-to-pmem.io/><p>Contribute <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/community/#newsletter><p>Newsletter <i class=icon-angle-right></i></p></a></div><div class="fbox-content h-bg-light"><a href=/community/#social-media><p>Social Media <i class=icon-angle-right></i></p></a></div></div></div></div></div></div></li><li class=menu-item><a class=menu-link href=https://pmem.io/solutions><div>Solutions</div></a></li><li class=menu-item><a class=menu-link href=https://pmem.io/blog><div>Blog</div></a></li><li class=menu-item><a class=menu-link href=https://pmem.io/about><div>About</div></a></li></ul></nav><form class=top-search-form method=get><input id=bcs-searchbox aria-label="Search input" type=text name=q class="form-control bcs-searchbox pt-4" placeholder="Type & Hit Enter.." autocomplete=off></form></div></div></div><div class="header-wrap-clone dark-mode"></div></header><div id=customSearch><div id=bcs_js_snippet></div></div><section id=content><div class="content-wrap dark-mode"><div class="container clearfix"><div class="row gutter-40 col-mb-80"><div class="postcontent col-lg-9 order-lg-last"><div class="single-post mb-0"><div class="entry clearfix"><div class=entry-title><h2>300 nanoseconds (2 of 2)</h2></div><div class=entry-meta><ul><li><i class=icon-calendar3></i> 26 Mar, 2020</li><li><i class=icon-user></i> Pbalcer</li><li><i class=icon-folder-open></i>
Perf300</li></ul></div><div class="entry-content mt-0"><p>At the end of the <a href=/blog/2019/12/300-nanoseconds-1-of-2>first</a> part of
this blog series, I posed three fundamental questions regarding the design of
<em>failure atomic data structures</em> for persistent memory.</p><ol><li>What does it mean to allocate persistent memory?</li><li>How to do fail-safe atomic updates?</li><li>Are all data structures suitable for persistent memory?</li></ol><p>This time around, I will try to answer these questions to the best of my ability.
We will return to the doubly-linked list example to see how it can be
modified for PMEM. Finally, I will briefly discuss the evolution of
libpmemobj as we refined its internal algorithms for the best performance.</p><h2 id=dynamic-memory-allocation-of-persistent-memory>Dynamic memory allocation of Persistent Memory</h2><p>Let&rsquo;s imagine we are just starting to create our very first persistent memory
program, a simple note-taking application. Since PMEM is exposed by the
operating system using files, our first step has to include opening and memory mapping
one. That gives us a pointer to N bytes of contiguous virtual address space which
directly represents the underlying persistent memory. Yay!</p><p>Now what?</p><p>We could simply lay out everything statically in memory, limiting the functionality
of our application - with this approach the size and the number of notes
we could take would be predefined.</p><p><img src=/images/posts/300n2_notes_static.png alt=notes_static></p><p>But we are more ambitious than that, we want to dynamically manage the number
of notes and how big they are. We need something that will manage our
region of memory and keep track of which bytes already contain a note and which
don&rsquo;t.
That something is usually referred to as memory allocator or, less commonly, a
heap manager.</p><p><img src=/images/posts/300n2_notes_dynamic.png alt=notes_dynamic></p><p>The two most important properties of traditional memory allocators are:</p><ul><li>Time efficiency - the number of cycles it takes to perform an allocation.</li><li>Space efficiency - the size and amount of gaps in-between allocated memory blocks.</li></ul><p>There are many ways of accomplishing those goals. We describe a couple in
Chapter 16 of the <a href=https://www.apress.com/us/book/9781484249314>Programming Persistent Memory book</a>.
In this post, we are going to focus on two properties important for
a persistent memory allocator, namely correctness and failure safety.</p><p>Our note-taking app wouldn&rsquo;t be very useful if there were no way of reconnecting
back to the existing file after restarting the application. And so, when
implementing an allocator the heap layout needs to be laid out in a way
that allows for a quick rediscovery of available free memory blocks.</p><p>One way of accomplishing that is to implement all tracking data structures
directly on persistent memory. For complex allocators, it usually means
a couple of different dynamic ordered and unordered containers. For scalable
allocators, we&rsquo;d also need a way to divide memory areas between different threads
which efficiently redistributes free space after a restart.</p><p>I&rsquo;ve spent many weeks tilting at that particular windmill&mldr;</p><p>While this approach of &ldquo;simply&rdquo; making everything persistent is certainly doable,
it quickly becomes complex and just&mldr; slow. PMEM has higher access latency, and
on top of that, we can&rsquo;t forget about fail-safety.
Allocators also tend to frequently re-use the same memory locations with the
goal of increasing the chance of cache hits. Well, if you have to evict the
memory from the cache after a store to make it persistent, it&rsquo;s a recipe for
a guaranteed cache-miss.</p><p><img src=/images/posts/300n2_heap_all_pmem.png alt=heap_static></p><p>So, what can we do instead? We can learn a lesson from how file systems solve
similar problems. We can design our on-media layout such that all the metadata is
compact and quick to iterate over and have separate runtime-only data structures
that are used to manage the persistent state. This enables the heap recovery process
to still be nearly instantaneous, while significantly improving runtime performance.
In libpmemobj, the allocator only needs to look at about 256 kilobytes of
metadata for every 16 gigabytes of memory to rebuild all the necessary
data structures and it does so lazily, which further reduces the recovery time.</p><p>Coincidentally, separating runtime bookkeeping from the persistent state is also
beneficial for fail-safety. We can now retrieve a free block from the
runtime state, populate it with data, and only then perform the
persistent state changes that mark the block as allocated. This is how
libpmemobj now maintains the fail-safety of memory allocations within a transaction.
Transactional allocation only retrieves a free block from the runtime data
structures, and only while the transaction is being committed, the persistent
state is updated.
Turns out this is both faster and simpler to implement than the alternative.</p><p><img src=/images/posts/300n2_heap_hybrid.png alt=heap_hybrid></p><p>Going back to the note-taking application, the described approach enables
us to first reserve a new note, write something in it, and only once it is
complete, make it persistently allocated and reachable.</p><h2 id=fail-safe-atomic-updates>Fail-safe atomic updates</h2><p>A fail-safe memory allocator is only a piece of the puzzle.
We also need to consider how to update existing memory locations in a way that the
assumptions about the application&rsquo;s data structures hold even in the presence of
failures.</p><p>To visualize the problem, let&rsquo;s look at the linked list again:
<img src=/images/posts/300n_linkedlist.png alt=map_insert></p><p>This data structure is consistent only if all of the following conditions are met:</p><ol><li>The first node&rsquo;s <code>prev</code> pointer is <code>NULL</code> or a sentinel object.</li><li>The last node&rsquo;s <code>next</code> pointer is <code>NULL</code> or a sentinel object.</li><li>For every two nodes <code>A</code> and <code>B</code>, if <code>A->next</code> points to <code>B</code>, then <code>B->prev</code> must
be pointing to <code>A</code>.</li></ol><p>While the first two conditions can be met without much of an issue, the last
condition requires that the modification of multiple variables must be atomic.
Like we discussed previously if this were about concurrency, we&rsquo;d protect
the insert operation of the linked list with a lock. But that&rsquo;s not the type
of atomicity we are after. We need this operation to be failure atomic, meaning
that the conditions we&rsquo;ve outlined need to still be true even in the
presence of failures.</p><p>There are two common solutions to this problem, redo and undo logging. Each with
different performance and usability tradeoffs. To illustrate how these two types
of logs work, we will go over how a fail-safe insert to a linked list can be
implemented using both redo and undo logs.</p><p>But before we do that, let&rsquo;s take a look at the steps required for a failure atomic linked list insert.</p><ol><li>A new object must be allocated and populated with data, which includes the <code>next</code> and <code>prev</code> pointers.</li><li>The <code>next</code> pointer of the predecessor node must be updated with the address of the new object.</li><li>The <code>prev</code> pointer of the successor node must be updated with the address of the new object.</li></ol><p>While the pointer updates are self-explanatory, the allocation must also
happen alongside all other changes. This is where the allocator design I&rsquo;ve described
in the previous section comes into play. In optimized implementations, the insert
operation can first reserve the new object, fill it, and update the persistent state
for the allocation alongside other changes in the log.</p><p>For the sake of simplicity, in the diagrams below I use the terms <code>alloc()</code> and <code>free()</code> to
indicate what happens to the new object. For the described design, this means &ldquo;update
the persistent metadata to match the new state of the object&rdquo;.</p><p>With that out of the way, let&rsquo;s finally take a look at the redo log.</p><p><img src=/images/posts/300n2_linkedlist_redo.png alt=map_redo></p><p>With the redo approach, the data to be modified is stored in the log prior to any
changes on the objects in the data structure. Only when all of the changes are staged
in the log, and some sort of a finish flag is set, the log is processed and all the
changes are applied. If this process were to be interrupted for whatever reason,
it can be simply repeated until successful and the finish flag is cleared.</p><p>The obvious consequence of using a redo log is that changes to data structures are
not immediately visible. This might be both a good or a bad thing, depending on
how you look at it. For example, this behavior plays better with a multi-threaded
code where the goal is to hide partial state changes anyway.</p><p>But what about performance? Well, in our experience with libpmemobj,
redo logs are a natural fit for buffering in a faster medium (DRAM) before
being written out sequentially to a slower one (PMEM). Writing and flushing one
bigger buffer instead of three smaller ones, like in our linked list example, is obviously faster.</p><p><img src=/images/posts/300n2_linkedlist_undo.png alt=map_undo></p><p>Undo log is similar, but instead of creating logs of the new data, it creates
snapshots of the memory regions just prior to modification. If the transaction is
aborted halfway through, the log will be used to rollback any changes that might have been
done to the data structure. In some implementations, such undo log would also have to deallocate
any objects that were created as part of the transaction. And that&rsquo;s precisely what
libpmemobj did in old versions (before 1.4). We&rsquo;ve since optimized this path so that no
persistent metadata is modified as part of transactional allocation, and objects are
only marked as allocated during the transaction&rsquo;s commit.</p><p>Undo logs are useful because they enable immediate visibility of changes to memory,
which just happens to be exactly what normal programming model with loads and stores
provides. All we have to do to modify an existing application is to add
instrumentation before all modifications and things generally just work.</p><p>However, using undo logs this way has performance implications.
The more individual synchronous transfers have to be done, the larger the overall
overhead for the transaction. This is the reason why we have added redo-log based
APIs and simple undo log batching to libpmemobj.</p><p>We&rsquo;ve now learned how to create a failure atomic doubly linked list. Now all that
remains is to ask ourselves if that&rsquo;s even a good idea to begin with.
And yes, I realize the order of these actions is a little backward, but it&rsquo;s the
order in which we did it, so&mldr; :)</p><h2 id=failure-atomic-data-structures>Failure Atomic Data Structures</h2><p>The feasibility of a data structure is ultimately determined by its usability and
performance for a given use case.
In libpmemobj we initially used intrusive doubly linked lists to store individual
transaction log entries. While this had its benefits, like relative design
simplicity (the implementation was anything but simple), its task was better
served by specialized buffer log data structure that we were able to implement
with almost 0 cache-misses in the write path. The performance improvements
shown in the previous post can be in large parts attributed to the continued
refinement of this log data structure.</p><p>But that&rsquo;s only one use case, what about everything else? In my opinion
the two most important things to look for in a potential failure atomic data
structure are a) the amount of non-contiguous small writes it does and b) a
cache friendly access pattern.</p><p>For example, a vector is a better failure atomic data structure compared to a
linked list, because its insert operation is very simple and it doesn&rsquo;t do any
pointer chasing during iteration. This might seem obvious, but I think it&rsquo;s
still worth saying. There are some scenarios where a list is necessary,
but more often than not there&rsquo;s a way around it that can use a vector or
something with similar characteristics.</p><p>A little less obvious example are binary trees. While a regular B-Tree can still
be considered a good data structure for Persistent Memory, it does have
a fairly complex insert (and remove) operation that needs to be heavily
optimized to avoid excessive transaction overhead. The same is true for red-black or
AVL trees, which, from our experiments, perform poorly when made to be failure atomic.
This is mostly due to the considerable depth of the trees and complex insert/remove
operations.
We found that better failure atomic ordered data structures are height optimized
compact <a href=https://www.the-paper-trail.org/post/art-paper-notes/>tries</a>, such as
<a href=https://db.in.tum.de/~leis/papers/ART.pdf>ART</a>
or
<a href=https://dbis-informatik.uibk.ac.at/sites/default/files/2018-06/hot-height-optimized.pdf>HOT</a>.
The reason for this is because they allow for densely packed nodes and have trivial
insert operations.</p><p>As for hash tables, the same general ideas apply. Separate chaining will
increase the number of cache misses and is likely to have a more write intensive
insert and remove operations. In our experiments, open addressing schemes
such as simple linear probing or Robin Hood hashing perform fairly well.</p><p>It&rsquo;s also possible to combine both PMEM and DRAM to achieve higher performance.
This approach can be successfully employed with careful coding and
consideration for pros and cons - you wouldn&rsquo;t want to wait hours for your
index to rebuild, would you? But that&rsquo;s a topic for a different post.</p><h2 id=summary>Summary</h2><p>Throughout this short series, I have discussed the various challenges associated
with writing high performance code for Persistent Memory. I also covered
different approaches to tackling those challenges based on my experience with
libpmemobj&rsquo;s implementation. And finally, I briefly shared my thoughts on
failure atomic data structure design.</p><p>Thanks for sticking with me, I hope this was interesting :)</p><div class=clear></div><div class="si-share border-0 d-flex justify-content-between align-items-center"><span>Share this Post:</span><div id=share-buttons><div class="social-icon si-borderless si-facebook" title="Share this on Facebook" onclick='window.open("http://www.facebook.com/share.php?u=https://pmem.io/blog/2020/03/300-nanoseconds-2-of-2/")'><i class=icon-facebook></i>
<i class=icon-facebook></i></div><div class="social-icon si-borderless si-twitter" title="Share this on Twitter" onclick='window.open("http://twitter.com/intent/tweet?text=300 nanoseconds (2 of 2)&url=https://pmem.io/blog/2020/03/300-nanoseconds-2-of-2/")'><i class=icon-twitter></i>
<i class=icon-twitter></i></div><div class="social-icon si-borderless si-linkedin" title="Share this on Linkedin" onclick='window.open("https://www.linkedin.com/shareArticle?mini=true&url=https://pmem.io/blog/2020/03/300-nanoseconds-2-of-2/&title=&summary=&source=")'><i class=icon-linkedin></i>
<i class=icon-linkedin></i></div><div class="social-icon si-borderless si-pinterest" title="Share this on Pinterest" onclick='window.open("https://pinterest.com/pin/create/button/?url=&media=&description=")'><i class=icon-pinterest></i>
<i class=icon-pinterest></i></div><div class="social-icon si-borderless si-email3" title="Share this through Email" onclick='window.open("mailto:?&body=https://pmem.io/blog/2020/03/300-nanoseconds-2-of-2/")'><i class=icon-email3></i>
<i class=icon-email3></i></div></div></div></div></div><div class="row justify-content-between col-mb-30 post-navigation"><div class="col-12 col-md-auto text-center"><a href="https://pmem.io/blog/2020/05/introduction-to-llpl/?ref=footer">&lArr; Introduction to LLPL</a></div><div class="col-12 col-md-auto text-center"><a href="https://pmem.io/blog/2020/03/language-bindings-for-pmemkv/?ref=footer">Language bindings for pmemkv &rArr;</a></div></div><div class=line></div><h4>Related Posts:</h4><div class="related-posts row posts-md col-mb-30"><div class="entry col-12 col-md-6"><div class="grid-inner row align-items-center gutter-20"><div class=col-4><div class=entry-image><a href=https://pmem.io/blog/2019/12/300-nanoseconds-1-of-2/ data-lightbox=image><img src=/images/pmem_logo.png alt="300 nanoseconds (1 of 2)"></a></div></div><div class=col-8><div class="entry-title title-xs"><h3><a href=https://pmem.io/blog/2019/12/300-nanoseconds-1-of-2/>300 nanoseconds (1 of 2)</a></h3></div><div class=entry-meta><ul><li><i class=icon-user></i> Pbalcer</li><li><i class=icon-calendar3></i> 19 Dec, 2019</li></ul></div></div></div></div></div></div></div><div class="sidebar col-lg-3"><div class=sidebar-widgets-wrap><div class="widget clearfix"><h4>Tag Cloud</h4><div class=tagcloud><a href=/tags/pmem class=block role=button>pmem</a>
<a href=/tags/persistent-memory class=block role=button>persistent-memory</a>
<a href=/tags/ndctl class=block role=button>ndctl</a>
<a href=/tags/pmdk class=block role=button>pmdk</a>
<a href=/tags/cxl class=block role=button>cxl</a>
<a href=/tags/daxctl class=block role=button>daxctl</a>
<a href=/tags/memkind class=block role=button>memkind</a>
<a href=/tags/async class=block role=button>async</a>
<a href=/tags/asynchronous class=block role=button>asynchronous</a>
<a href=/tags/concurrency class=block role=button>concurrency</a>
<a href=/tags/configure class=block role=button>configure</a>
<a href=/tags/dax class=block role=button>dax</a>
<a href=/tags/install class=block role=button>install</a>
<a href=/tags/intro class=block role=button>intro</a>
<a href=/tags/miniasync class=block role=button>miniasync</a>
<a href=/tags/setup class=block role=button>setup</a>
<a href=/tags/dml class=block role=button>dml</a>
<a href=/tags/dsa class=block role=button>dsa</a>
<a href=/tags/faq class=block role=button>faq</a>
<a href=/tags/imdb class=block role=button>imdb</a>
<a href=/tags/memory class=block role=button>memory</a>
<a href=/tags/pmem-use-case class=block role=button>pmem-use-case</a>
<a href=/tags/pmem2 class=block role=button>pmem2</a>
<a href=/tags/sanitize class=block role=button>sanitize</a>
<a href=/tags/secure-erase class=block role=button>secure-erase</a>
<a href=/tags/sql class=block role=button>sql</a>
<a href=/tags/tiering class=block role=button>tiering</a>
<a href=/tags/2019 class=block role=button>2019</a>
<a href=/tags/blogs class=block role=button>blogs</a>
<a href=/tags/crash class=block role=button>crash</a></div></div></div></div></div></div></div></section><footer id=footer class="border-0 bg-white"><div id=copyrights><div class="container clearfix"><div class="row justify-content-between col-mb-30"><div class="col-12 col-lg-auto text-center text-lg-start"><div id=logo><a href=/ class=standard-logo data-dark-logo=images/logo-dark.png><img src=https://pmem.io/images/pmem_logo.png alt="PMem Logo"></a>
<a href=/ class=retina-logo data-dark-logo=images/logo-dark@2x.png><img src=https://pmem.io/images/pmem_logo.png alt="PMem Logo"></a></div></div><div class="col-12 col-lg-auto text-center text-lg-end"><div class="copyrights-menu copyright-links clearfix text-uppercase"><a href=https://pmem.io/about>about</a>/
<a href=https://pmem.io/blog>blog</a>/
<a href=https://pmem.io/community>community</a>/
<a href=https://pmem.io/cookies.html>Cookies</a>/
<a href=https://pmem.io/developer-hub>developer Hub</a>/
<a href=https://pmem.io/learn>learn</a>/
<a href=https://pmem.io/privacy.html>Privacy</a>/
<a href=https://pmem.io/solutions>solutions</a>/
<a href=https://pmem.io/terms.html>Terms</a></div><div class="col-lg-auto text-center mt-0"><p>Copyright &copy; 2023 pmem.io</p></div></div></div></div></div></footer></div><div id=gotoTop class=icon-angle-up></div><script src=/js/jquery.js></script>
<script src=/js/plugins.min.js></script>
<script src=/js/custom.js></script>
<script src=/js/darkmode.js></script>
<script src=/js/functions.js></script>
<script type=text/javascript src="https://ui.customsearch.ai/api/ux/rendering-js?customConfig=011a90aa-26ea-46b5-bf60-4b5b407c72c6&market=en-US&version=latest&q="></script></body></html>